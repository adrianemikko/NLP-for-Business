{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-BP-L2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2\n",
        "**Name**: Adriane Mikko Amorado<br>\n",
        "**Course Name**: Solving Business Problems with NLP<br>\n",
        "**Instructor**: Juber Rahman"
      ],
      "metadata": {
        "id": "5IBK1d6_KjCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "eVBW-n3ARH23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import requests\n",
        "\n",
        "import gensim\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "kGTnnMjjPKJW",
        "outputId": "db5ad1e9-420b-4840-a84f-42e3d712f389",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "YnZczXF1RKVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Select a book of your choice from project Gutenberg https://www.gutenberg.org/"
      ],
      "metadata": {
        "id": "1y59M_zMLpFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.gutenberg.org/files/15420/15420.txt'"
      ],
      "metadata": {
        "id": "cqDH6JzTT2kg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Load the text in your python workspace"
      ],
      "metadata": {
        "id": "HZ9MpEZFLnxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = requests.get(url)"
      ],
      "metadata": {
        "id": "s0EioHC7Ls9M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Do topic modeling on the text after due preprocessing, vectorization etc."
      ],
      "metadata": {
        "id": "PxKGkvyWLmey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data2docs(data):\n",
        "    docs = pd.Series([doc.strip() for doc in data.text.split('\\r\\n\\r\\n') if doc])\n",
        "    start = docs.index[docs.str.startswith('*** START OF THIS PROJECT GUTENBERG EBOOK')]\n",
        "    end = docs.index[docs.str.startswith('*** END OF THIS PROJECT GUTENBERG EBOOK')]\n",
        "    return docs.loc[start[0]+1: end[0]-1]"
      ],
      "metadata": {
        "id": "4_5iSgb3RPLe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = data2docs(data)"
      ],
      "metadata": {
        "id": "LJWFzQkW89pu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(doc):\n",
        "    \"\"\"Tokenizes docs by applying pos with lemmatizer for each token\"\"\"\n",
        "    tokenizer = RegexpTokenizer(r'(?u)\\b(\\w(?:\\w|\\-)+)\\b')\n",
        "    tokens = tokenizer.tokenize(doc)\n",
        "\n",
        "    postags = [\n",
        "        (token.lower(), 'a' if pos[0] == 'J' else pos[0].lower())\n",
        "        for token, pos in nltk.pos_tag(tokens)\n",
        "        if pos[0] in 'JNVR']\n",
        "    \n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = [lemmatizer.lemmatize(*t) for t in postags]\n",
        "\n",
        "    return lemmas"
      ],
      "metadata": {
        "id": "JBOAx1N4U0zZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"bow\", CountVectorizer(\n",
        "            tokenizer=tokenizer,\n",
        "            stop_words=stopwords.words('english')\n",
        "        )),\n",
        "        (\"lda\", LatentDirichletAllocation(\n",
        "            n_components=5,             \n",
        "            max_iter=10,             \n",
        "            learning_method='online',\n",
        "            random_state=100,        \n",
        "            batch_size=128,          \n",
        "            evaluate_every=-1,     \n",
        "            n_jobs = -1\n",
        "        )),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Cb3huvvAPveJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_pipeline.fit(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4vr9dX799Bk",
        "outputId": "5f7e985a-8972-4eca-d8f1-50834c6cda07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('bow',\n",
              "                 CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
              "                                             'our', 'ours', 'ourselves', 'you',\n",
              "                                             \"you're\", \"you've\", \"you'll\",\n",
              "                                             \"you'd\", 'your', 'yours',\n",
              "                                             'yourself', 'yourselves', 'he',\n",
              "                                             'him', 'his', 'himself', 'she',\n",
              "                                             \"she's\", 'her', 'hers', 'herself',\n",
              "                                             'it', \"it's\", 'its', 'itself', ...],\n",
              "                                 tokenizer=<function tokenizer at 0x7f214b52a560>)),\n",
              "                ('lda',\n",
              "                 LatentDirichletAllocation(learning_method='online',\n",
              "                                           n_components=5, n_jobs=-1,\n",
              "                                           random_state=100))])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log Likelihood: Higher the better\n",
        "print(\"Log Likelihood: \", bow_pipeline.score(docs))\n",
        "\n",
        "# Perplexity: Lower the better. \n",
        "print(\"Perplexity: \", bow_pipeline['lda'].perplexity(bow_pipeline['bow'].transform(docs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lySuR92i-ZRd",
        "outputId": "2bc2c947-8df9-4251-bf52-ee0f3c2cf9f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Likelihood:  -146026.15554281248\n",
            "Perplexity:  1978.534148551787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"tfidf\", TfidfVectorizer(\n",
        "            tokenizer=tokenizer,\n",
        "            stop_words=stopwords.words('english')\n",
        "        )),\n",
        "        (\"lda\", LatentDirichletAllocation(\n",
        "            n_components=5,             \n",
        "            max_iter=10,             \n",
        "            learning_method='online',\n",
        "            random_state=100,        \n",
        "            batch_size=128,          \n",
        "            evaluate_every=-1,     \n",
        "            n_jobs = -1\n",
        "        )),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "zAajPHZrUna7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_pipeline.fit(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp2SLAqhUuW7",
        "outputId": "bbad2e9b-1f0f-47c3-a2f9-17051cc2be9e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
              "                                             'our', 'ours', 'ourselves', 'you',\n",
              "                                             \"you're\", \"you've\", \"you'll\",\n",
              "                                             \"you'd\", 'your', 'yours',\n",
              "                                             'yourself', 'yourselves', 'he',\n",
              "                                             'him', 'his', 'himself', 'she',\n",
              "                                             \"she's\", 'her', 'hers', 'herself',\n",
              "                                             'it', \"it's\", 'its', 'itself', ...],\n",
              "                                 tokenizer=<function tokenizer at 0x7f214b52a560>)),\n",
              "                ('lda',\n",
              "                 LatentDirichletAllocation(learning_method='online',\n",
              "                                           n_components=5, n_jobs=-1,\n",
              "                                           random_state=100))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log Likelihood: Higher the better\n",
        "print(\"Log Likelihood: \", tfidf_pipeline.score(docs))\n",
        "\n",
        "# Perplexity: Lower the better. \n",
        "print(\"Perplexity: \", tfidf_pipeline['lda'].perplexity(tfidf_pipeline['tfidf'].transform(docs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBmaecs6U4Ey",
        "outputId": "a34411af-9de9-4c79-c09d-d333454369e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Likelihood:  -25222.619218228218\n",
            "Perplexity:  11524.04667413381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. How many topics are there, what are they?"
      ],
      "metadata": {
        "id": "7YCywdtzLk1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GVRnPGxNvuJ",
        "outputId": "31c2abfc-5cd1-480a-8ec6-e5a6e1119458"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (4.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "pyLDAvis.enable_notebook()\n",
        "panel = pyLDAvis.sklearn.prepare(\n",
        "    bow_pipeline['lda'],\n",
        "    bow_pipeline['bow'].transform(docs),\n",
        "    bow_pipeline['bow'], \n",
        "    mds='tsne')\n",
        "panel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SFZxSw0-NVIs",
        "outputId": "27452232-0c35-490d-d1e6-e90c7151bd62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Mapping\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:827: FutureWarning: 'square_distances' has been introduced in 0.24 to help phase out legacy squaring behavior. The 'legacy' setting will be removed in 1.1 (renaming of 0.26), and the default setting will be changed to True. In 1.3, 'square_distances' will be removed altogether, and distances will be squared by default. Set 'square_distances'=True to silence this warning.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el21981397808389411361870018081\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el21981397808389411361870018081_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [52.66812934018873, 18.489188423700973, 14.156125524565505, 12.810700572158204, 1.8758561393865816]}, \"tinfo\": {\"Term\": [\"social\", \"marriage\", \"court\", \"state\", \"desertion\", \"relation\", \"law\", \"worker\", \"city\", \"york\", \"new\", \"probation\", \"find\", \"domestic\", \"view\", \"colcord\", \"see\", \"family\", \"home\", \"divorce\", \"sex\", \"volume\", \"treatment\", \"joanna\", \"legal\", \"work\", \"case\", \"disaster\", \"woman\", \"service\", \"return\", \"leave\", \"week\", \"send\", \"household\", \"later\", \"away\", \"finally\", \"tell\", \"help\", \"management\", \"receive\", \"money\", \"friend\", \"month\", \"want\", \"florence\", \"nesbitt\", \"refuse\", \"letter\", \"go\", \"father\", \"enough\", \"local\", \"employment\", \"willing\", \"think\", \"likely\", \"aleck\", \"complaint\", \"little\", \"long\", \"visitor\", \"man\", \"husband\", \"wife\", \"get\", \"year\", \"take\", \"never\", \"time\", \"keep\", \"way\", \"child\", \"make\", \"come\", \"woman\", \"say\", \"place\", \"work\", \"home\", \"give\", \"family\", \"case\", \"city\", \"back\", \"good\", \"bring\", \"worker\", \"often\", \"order\", \"deserter\", \"find\", \"know\", \"court\", \"probation\", \"social\", \"desertion\", \"issue\", \"announcement\", \"training\", \"facility\", \"combine\", \"self-control\", \"139-140\", \"teach\", \"25-26\", \"seybert\", \"forward\", \"frequently\", \"gamble\", \"depend\", \"examination\", \"organize\", \"choose\", \"disposition\", \"expert\", \"list\", \"mellor\", \"distinct\", \"longer\", \"hebrew\", \"inferiority\", \"alfred\", \"antagonism\", \"rehabilitation\", \"capacity\", \"disintegrate\", \"number\", \"philadelphia\", \"municipal\", \"book\", \"income\", \"mental\", \"therefore\", \"subsequent\", \"interference\", \"testimony\", \"recreation\", \"factor\", \"juvenile\", \"court\", \"community\", \"effect\", \"character\", \"relation\", \"probation\", \"reconciliation\", \"worker\", \"family\", \"poor\", \"write\", \"case\", \"desertion\", \"officer\", \"however\", \"social\", \"problem\", \"study\", \"domestic\", \"cause\", \"deserter\", \"make\", \"good\", \"marriage\", \"bureau\", \"many\", \"wife\", \"colcord\", \"joanna\", \"disaster\", \"foundation\", \"russell\", \"sage\", \"cross\", \"red\", \"field\", \"preparation\", \"gather\", \"byron\", \"deacon\", \"project\", \"cloth\", \"ebook\", \"price\", \"gutenberg\", \"brief\", \"message\", \"expression\", \"embody\", \"fewer--having\", \"this--can\", \"lucidly\", \"compass\", \"volume\", \"mary\", \"broken\", \"welfare\", \"view\", \"general\", \"social\", \"publication\", \"cent\", \"american\", \"treatment\", \"group\", \"service\", \"find\", \"see\", \"home\", \"fact\", \"desertion\", \"work\", \"case\", \"worker\", \"many\", \"deserter\", \"men\", \"family\", \"know\", \"first\", \"much\", \"relief\", \"racial\", \"brandt\", \"divorce\", \"st\", \"34-35\", \"correction\", \"crisis\", \"ceremony\", \"legislation\", \"lilian\", \"pregnancy\", \"44-45\", \"45-46\", \"chicago\", \"summary\", \"vagary\", \"marriages\", \"verification\", \"193-199\", \"spouse\", \"37-39\", \"false\", \"extradite\", \"protective\", \"misdemeanor\", \"101-102\", \"motion\", \"_sex\", \"forel\", \"immorality\", \"york\", \"conference\", \"marriage\", \"incompatibility\", \"sexual\", \"term\", \"legal\", \"treaty\", \"sex\", \"law\", \"percentage\", \"domestic\", \"new\", \"educational\", \"equity\", \"relation\", \"state\", \"common\", \"jewish\", \"union\", \"also\", \"desertion\", \"charity\", \"extradition\", \"city\", \"difference\", \"court\", \"bureau\", \"protection\", \"study\", \"cause\", \"woman\", \"marry\", \"child\", \"wife\", \"case\", \"man\", \"footnote\", \"loane\", \"donald\", \"patrick\", \"survive\", \"_queen\", \"drinker\", \"queen\", \"edward\", \"viii\", \"nerve\", \"weakened\", \"dormant\", \"destroyed\", \"resourcefulness\", \"alive\", \"well-nigh\", \"wrong-doing\", \"incentive\", \"attainment\", \"change--the\", \"fresh\", \"_is_\", \"shake\", \"disappearance\", \"envelope\", \"passion\", \"castin\", \"version\", \"unconscious\", \"instability\", \"imagination\", \"demand\", \"perhaps\", \"feeling\", \"content\", \"desire\", \"wanderlust\", \"resort\", \"urge\", \"realize\", \"relationship\", \"jealousy\", \"gradually\", \"develop\", \"motif\", \"poor\", \"mind\", \"future\", \"failure\", \"ill\", \"story\", \"well\", \"sex\"], \"Freq\": [153.0, 75.0, 147.0, 65.0, 152.0, 70.0, 56.0, 141.0, 71.0, 34.0, 51.0, 76.0, 92.0, 34.0, 27.0, 21.0, 61.0, 197.0, 113.0, 20.0, 27.0, 21.0, 39.0, 18.0, 24.0, 110.0, 187.0, 17.0, 90.0, 33.0, 35.69706359207887, 37.68925622773562, 23.471028357193664, 26.670243887232136, 19.879839401350846, 25.954146716528978, 20.981029363214155, 19.18346810071431, 18.56066532472487, 23.159832539274166, 17.241507536481784, 19.39890329302165, 17.70166350497838, 15.77544853449874, 23.960724746807415, 14.984813216292148, 14.317655135793915, 14.31900246802718, 14.220921173037816, 26.92141406923683, 60.28770173957153, 14.524706697063873, 16.84253417480409, 15.406982157027095, 12.313681825415143, 13.256200464155995, 14.754472055781262, 19.496567590724315, 10.724335290920925, 11.2826167405324, 26.074501356037054, 33.18309445704774, 27.35922337841695, 212.328262444221, 67.19066582637956, 143.13371519527112, 43.10017724083095, 52.89288940355668, 77.2787728660859, 26.483150341665816, 63.391237296953015, 31.620289427267334, 26.323511697371057, 83.57088869293518, 103.02713996108018, 49.635146422557355, 71.87818903756093, 53.422260563063084, 40.14687434104799, 76.98595407393411, 77.11142350239594, 48.260441900442785, 113.7165373919231, 106.99822723397958, 51.848694632861395, 33.964830048841435, 44.89071451417905, 37.00820477096858, 72.83158386154054, 38.5615835053715, 32.14894822953456, 56.30743161513573, 52.884925144210264, 40.80280855187206, 62.070882188883985, 45.64465259634152, 57.355357336454645, 51.89653032130357, 18.22853386089785, 12.081913123070736, 8.773700759396744, 6.720603188613228, 4.284360881027736, 4.151693284016228, 3.676204083873167, 4.108909428483885, 3.626912230995017, 3.552044506405475, 13.541804781157825, 3.80225393818126, 3.3828405542773563, 3.339173173634394, 3.4996676633438057, 4.610735743554616, 3.7616444264103572, 5.817263063337093, 2.6956884730251853, 5.3632682019258615, 2.5916116992622498, 2.587760806673473, 2.6153523731864405, 2.637759536964038, 2.5407230871089452, 2.5133214595767988, 2.49829464815048, 2.562284431302412, 2.4605520059764516, 2.5534752413696196, 10.863641220478302, 11.588361956539716, 3.749465178416251, 14.96445613000589, 6.554377925908986, 10.787896742080603, 6.885164548868617, 3.0164200040954947, 5.674372801826447, 5.545568916291284, 7.767427941120567, 16.019705215329378, 9.250463116046738, 59.73381994102983, 13.503470216479162, 16.811866971237173, 8.225369990696283, 28.820460233283878, 30.390061067823222, 17.265482289271798, 44.325907242508414, 54.855151466465024, 9.487844924864701, 16.73181892435095, 43.93353358157644, 37.28588938021265, 18.76456462663878, 16.839749243978243, 32.003146746635636, 13.498211385559424, 14.470274227393768, 13.29037123145503, 14.828515772281264, 20.952148107194827, 19.345765486356104, 14.290667639782878, 13.441601567537907, 12.205033335785469, 12.321090150571331, 12.461151231914265, 21.089741895090505, 17.898217502953976, 16.820055009328584, 14.055707717612796, 12.346168840103823, 12.345064845655777, 12.395352741659439, 11.894090993761042, 11.307475600029727, 10.066005235895213, 9.537467739081466, 8.47901638917299, 8.479187790795898, 8.479452780280575, 8.478927293502391, 8.479089735032886, 8.478854660671846, 8.479490453507069, 8.46600657858962, 8.464549425338735, 8.4641478255997, 8.462422806442515, 8.460639587584893, 8.458168437105217, 8.453536870775652, 8.446888056321562, 18.820577044097643, 4.618530611668975, 9.558460033746583, 9.499567487387173, 22.578128791476626, 15.839700557340583, 63.79554487155642, 11.316435495717377, 13.299686740541079, 13.747056685883726, 18.869778981259277, 13.56175217141187, 16.55448442360381, 27.205541844996162, 20.98199546667535, 25.31054821917438, 14.898359050810145, 27.69001250750002, 23.91658774629481, 26.562635363664956, 23.92109117332867, 16.971336494551824, 19.124516974186356, 13.679699718351937, 21.391668988116905, 14.339971641556224, 13.54955216058917, 12.904345739574767, 12.680736512243628, 5.9231311360534775, 5.177827570226944, 17.772454902225164, 10.926262833771998, 4.87551562705738, 4.595679264549396, 4.336255971572521, 4.211183487139692, 4.0358696217080015, 3.9007871028804724, 6.4969192771612265, 3.3241896594436957, 3.3244458633399994, 5.442718193170277, 3.175474681672348, 3.1936450064780684, 3.090558230501399, 3.121061707371016, 3.216973152476763, 2.8788942227347154, 3.24067980159677, 2.8356329535241924, 2.9383006519636226, 3.460603492760912, 2.887351906758657, 2.5318200146609793, 2.5292265775458724, 2.5460637288229404, 2.424296190173815, 2.4214304142222653, 26.28785117321365, 5.646166360105947, 53.508579288450605, 9.369886493415372, 4.0927103521965185, 6.658421561310008, 16.677669323982553, 6.428975682847234, 17.913902468419412, 32.21886200610667, 5.820446208868477, 19.36257322654737, 26.030110545454527, 4.7826916990718455, 4.991839398546515, 30.46259586207342, 27.70642940395246, 11.96388133554716, 6.706609750532564, 9.149629932717822, 12.014973108681192, 35.373111329939995, 12.315793158508201, 8.844371223642414, 18.97595719378505, 9.20996826559127, 25.029566478382648, 14.560852583285827, 7.462885270678443, 11.772129694355005, 12.071743279063602, 13.890115877251253, 7.936363851271913, 10.955391638984052, 10.111115474058538, 10.118633794499663, 9.044974850633455, 3.2948571654530654, 1.0437741704166927, 0.9341091222137156, 0.6626494786343972, 0.5868964085941368, 0.40877004710083337, 0.39226058484458337, 0.37620000751888255, 0.37614429357826196, 0.37598556049969556, 0.3699250334990871, 0.36926384520230954, 0.3694333870655471, 0.36933813055212983, 0.36915571876137543, 0.3686242450946697, 0.36906228555723497, 0.3684111275601235, 0.36840133935211083, 0.3678869608985221, 0.3458739354936987, 0.3459055039784285, 0.34587505918526573, 0.3457539249477369, 0.34531521039796903, 0.6081291441650273, 0.3455616165079078, 0.3455450121294933, 0.3459739488427942, 0.34539947455772485, 0.9974708552743355, 0.617291526787294, 0.6361360538155572, 1.1125454737166491, 0.8660927657708862, 0.6018987162550885, 0.9489131678986409, 0.6420950441109363, 0.5378405668635375, 0.7281830543000698, 0.776176222190159, 0.5243643104630535, 0.5780690987446071, 0.48840820738286034, 0.7090218544247796, 0.5387200963778298, 0.8251394588339611, 0.8050990836746583, 0.5930261967637476, 0.5824474187312362, 0.5203378288624914, 0.6211982262908241, 0.6263463567057266, 0.5548790554450042], \"Total\": [153.0, 75.0, 147.0, 65.0, 152.0, 70.0, 56.0, 141.0, 71.0, 34.0, 51.0, 76.0, 92.0, 34.0, 27.0, 21.0, 61.0, 197.0, 113.0, 20.0, 27.0, 21.0, 39.0, 18.0, 24.0, 110.0, 187.0, 17.0, 90.0, 33.0, 36.51240370338217, 38.55576508127211, 24.098981181134995, 27.412635244396984, 20.484334878020384, 26.75608078708083, 21.684475774855333, 19.831323436643697, 19.189776001864807, 23.94806107214349, 17.842637695339093, 20.1228388174568, 18.371881589622745, 16.39681573070936, 24.924959117142812, 15.59642450032026, 14.909352843113734, 14.911130653928936, 14.840714992142406, 28.12370771752028, 62.99011706260184, 15.176366179344926, 17.624254146955252, 16.13948181511856, 12.918052184263864, 13.932886723441955, 15.520052279026787, 20.547566350235932, 11.314486561282667, 11.904868985038505, 27.536037308855292, 35.24100396443626, 29.1654230719977, 239.20600359578893, 75.91563330126141, 169.35854770179088, 48.08687792084263, 60.39810316244406, 91.01362950815286, 28.816217615472066, 73.96506664068367, 35.070260337031, 28.75990073523898, 104.59320213495248, 134.33311711146064, 58.7532808936837, 90.03833697280521, 64.77005282632419, 46.87512856341265, 110.68152355598332, 113.51157006884985, 63.40707814676832, 197.96996376769988, 187.7002380463253, 71.8211284432554, 40.355327213816764, 60.57032973312397, 46.67045311804192, 141.6047305881138, 51.03234272952164, 37.823494431611664, 103.23891553624257, 92.47362740070811, 58.132884717106336, 147.23294217348163, 76.54614280848416, 153.49315430645618, 152.36939856980962, 18.938696236948147, 12.707794977971032, 9.468043026540371, 7.407520900349307, 4.935964540227664, 4.825064579728269, 4.311681373959135, 4.8303440687940125, 4.266530122297322, 4.183000301657255, 16.0233030864655, 4.508884449139182, 4.018894277479747, 3.975208336532275, 4.169933564819714, 5.5440211170401446, 4.58975047203611, 7.128551471929356, 3.343095572018821, 6.6549886488282795, 3.22050257459587, 3.2189798399880094, 3.2559671010176694, 3.2924777211983756, 3.1761028469770376, 3.142796465032711, 3.1352842927213245, 3.2216810160138865, 3.0954344466778707, 3.215712706083779, 13.684385793121926, 15.249110850148675, 4.787472263856339, 20.56048702877858, 8.814203898350522, 15.445219240554659, 9.600152607465548, 3.832478312038679, 7.932412503677928, 7.783633749914354, 11.6180054869792, 27.733339993212418, 14.51930458641682, 147.23294217348163, 24.115860379524864, 32.398358972881994, 12.965035013059893, 70.79828230105927, 76.54614280848416, 36.62566555038187, 141.6047305881138, 197.96996376769988, 16.50530088172905, 37.92133273802938, 187.7002380463253, 152.36939856980962, 51.69273995818514, 44.342092173104284, 153.49315430645618, 32.62688896946905, 39.57834475287703, 34.88477346431051, 44.28791961353184, 103.23891553624257, 134.33311711146064, 60.57032973312397, 75.93158421727848, 52.212768976915676, 60.00624264456922, 169.35854770179088, 21.79169229514533, 18.60756549091366, 17.506228211791953, 14.743815109450045, 13.032833289690835, 13.032623088460843, 13.086989300590496, 12.582308507443877, 12.08152389535507, 10.761918928393285, 10.229584554745712, 9.164605027450513, 9.165258489266431, 9.165719793159242, 9.165548084506689, 9.165987527118206, 9.166047714781419, 9.167343217733379, 9.176117823552469, 9.175494410631034, 9.176459059583797, 9.177328487687143, 9.17868146290308, 9.181083258390306, 9.18378006096022, 9.188321947299933, 21.091155393534077, 5.313961381534607, 11.116595729229806, 11.104666247342534, 27.367986505839244, 19.982969716806828, 153.49315430645618, 14.167824803491804, 18.837936002248494, 20.842512137037442, 39.38195201125898, 22.14936015802038, 33.640950783731284, 92.47362740070811, 61.779203914409706, 113.51157006884985, 33.717415803272154, 152.36939856980962, 110.68152355598332, 187.7002380463253, 141.6047305881138, 60.00624264456922, 103.23891553624257, 34.032687755903474, 197.96996376769988, 58.132884717106336, 61.158738308700705, 44.91684482634937, 28.310398130754365, 6.570802544663033, 5.8402908663147635, 20.178161871355357, 12.467430950561637, 5.580224968687612, 5.264712100587367, 5.00929075002106, 4.901383129005205, 4.699860380097646, 4.546598373073943, 7.705922686243427, 3.9774744144075727, 3.978787003024804, 6.5591921201339245, 3.8285506336237867, 3.8730977721475446, 3.7521200162315047, 3.789685033916689, 3.9264100505056208, 3.5242322610120316, 3.982614886179568, 3.491206974132551, 3.6424122362037585, 4.309096172920588, 3.616398190421984, 3.1799107233543236, 3.179923600447398, 3.219098291666871, 3.0711517419309677, 3.070246257995167, 34.25202340985711, 7.237458856407236, 75.93158421727848, 12.467216979792248, 5.259581691751944, 8.966450116788879, 24.469268400366783, 8.710397619766177, 27.740212583010315, 56.53709432705375, 8.03970516709847, 34.88477346431051, 51.329930449451595, 6.423755268000293, 6.788491504699923, 70.79828230105927, 65.56259785453238, 22.124671475554408, 10.54475387182146, 16.492633438585994, 27.261682905653977, 152.36939856980962, 28.62773156581109, 18.185431891747566, 71.8211284432554, 20.0239724932353, 147.23294217348163, 52.212768976915676, 13.585583848094966, 39.57834475287703, 44.28791961353184, 90.03833697280521, 20.193884170122473, 104.59320213495248, 169.35854770179088, 187.7002380463253, 239.20600359578893, 4.053760943073213, 1.793915788829409, 1.6852324708448152, 1.4149323199158035, 1.4269010157310218, 1.1573930041266416, 1.143859740969587, 1.1257736247409214, 1.125809965988443, 1.1260784024062604, 1.135598861560951, 1.1349489858003468, 1.1356587182819093, 1.1359245464120646, 1.1378329494079693, 1.137497226882548, 1.1388949588315254, 1.1370595176963398, 1.1384699788321277, 1.1382090612482887, 1.0951769030367773, 1.0964315846625798, 1.0964128698713964, 1.096208279848982, 1.095030232030987, 1.928480439237246, 1.0961716009361389, 1.0961862384680208, 1.0977195433086862, 1.096094687855728, 3.4871465926842977, 2.0853908051232084, 2.2134289489013765, 4.551417874365645, 4.347491958340184, 3.1463155494386266, 7.782521069216774, 4.112157079677319, 2.900778446397115, 5.960172761312532, 7.188081372604195, 2.8296361969278445, 4.033733198732876, 2.5749993594159983, 8.332852813449389, 3.9367526964916832, 16.50530088172905, 19.084157649561384, 6.5166686011685675, 12.010690596776376, 8.099045550869882, 32.82403187576671, 48.282468030436796, 27.740212583010315], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.6485, -5.5942, -6.0678, -5.94, -6.2338, -5.9672, -6.1799, -6.2695, -6.3025, -6.0811, -6.3762, -6.2583, -6.3499, -6.4651, -6.0471, -6.5165, -6.562, -6.5619, -6.5688, -5.9306, -5.1244, -6.5477, -6.3996, -6.4887, -6.7128, -6.6391, -6.532, -6.2533, -6.851, -6.8003, -5.9626, -5.7215, -5.9145, -3.8654, -5.016, -4.2598, -5.46, -5.2553, -4.8761, -5.947, -5.0742, -5.7697, -5.9531, -4.7978, -4.5885, -5.3188, -4.9486, -5.2453, -5.531, -4.8799, -4.8783, -5.3469, -4.4898, -4.5507, -5.2752, -5.6982, -5.4193, -5.6124, -4.9354, -5.5713, -5.7532, -5.1927, -5.2554, -5.5148, -5.0953, -5.4026, -5.1743, -5.2743, -5.2737, -5.685, -6.005, -6.2715, -6.7217, -6.7532, -6.8748, -6.7636, -6.8883, -6.9092, -5.5709, -6.8411, -6.958, -6.971, -6.924, -6.6483, -6.8519, -6.4159, -7.1851, -6.4971, -7.2244, -7.2259, -7.2153, -7.2068, -7.2443, -7.2551, -7.2611, -7.2358, -7.2763, -7.2393, -5.7913, -5.7267, -6.8551, -5.471, -6.2966, -5.7983, -6.2473, -7.0726, -6.4408, -6.4637, -6.1268, -5.4029, -5.952, -4.0868, -5.5738, -5.3546, -6.0695, -4.8156, -4.7626, -5.328, -4.3851, -4.172, -5.9267, -5.3594, -4.394, -4.5581, -5.2447, -5.353, -4.7109, -5.5742, -5.5046, -5.5897, -5.4802, -5.1345, -5.2142, -5.5171, -5.5784, -5.6749, -5.6654, -5.6541, -4.8609, -5.025, -5.0871, -5.2666, -5.3963, -5.3964, -5.3924, -5.4336, -5.4842, -5.6005, -5.6544, -5.7721, -5.7721, -5.772, -5.7721, -5.7721, -5.7721, -5.772, -5.7736, -5.7738, -5.7738, -5.774, -5.7742, -5.7745, -5.7751, -5.7759, -4.9747, -6.3796, -5.6522, -5.6584, -4.7927, -5.1472, -3.754, -5.4834, -5.3219, -5.2888, -4.9721, -5.3024, -5.103, -4.6063, -4.866, -4.6785, -5.2084, -4.5886, -4.7351, -4.6302, -4.7349, -5.0781, -4.9587, -5.2938, -4.8467, -5.2466, -5.3033, -5.3521, -5.3696, -6.0309, -6.1654, -4.9322, -5.4186, -6.2256, -6.2847, -6.3428, -6.3721, -6.4146, -6.4486, -5.9385, -6.6086, -6.6085, -6.1155, -6.6543, -6.6486, -6.6815, -6.6716, -6.6414, -6.7524, -6.634, -6.7675, -6.732, -6.5684, -6.7495, -6.8809, -6.8819, -6.8753, -6.9243, -6.9254, -4.5407, -6.0788, -3.83, -5.5723, -6.4006, -5.9139, -4.9957, -5.949, -4.9242, -4.3373, -6.0484, -4.8465, -4.5506, -6.2448, -6.202, -4.3933, -4.4881, -5.3279, -5.9067, -5.5961, -5.3237, -4.2439, -5.2989, -5.63, -4.8666, -5.5895, -4.5897, -5.1315, -5.7999, -5.3441, -5.3189, -5.1786, -5.7384, -5.416, -5.4962, -5.4954, -5.6076, -4.6962, -5.8457, -5.9568, -6.3001, -6.4215, -6.7832, -6.8244, -6.8662, -6.8664, -6.8668, -6.883, -6.8848, -6.8844, -6.8846, -6.8851, -6.8866, -6.8854, -6.8871, -6.8872, -6.8886, -6.9503, -6.9502, -6.9503, -6.9506, -6.9519, -6.386, -6.9512, -6.9512, -6.95, -6.9516, -5.8911, -6.371, -6.3409, -5.7819, -6.0324, -6.3963, -5.941, -6.3316, -6.5088, -6.2058, -6.142, -6.5342, -6.4367, -6.6052, -6.2325, -6.5071, -6.0808, -6.1054, -6.4111, -6.4291, -6.5419, -6.3647, -6.3564, -6.4776], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6186, 0.6184, 0.6148, 0.6137, 0.6112, 0.6107, 0.6082, 0.6079, 0.6078, 0.6077, 0.6069, 0.6045, 0.604, 0.6025, 0.6017, 0.6012, 0.6007, 0.6006, 0.5985, 0.5975, 0.5973, 0.5973, 0.5958, 0.5947, 0.5932, 0.5914, 0.5906, 0.5887, 0.5876, 0.5875, 0.5866, 0.581, 0.5772, 0.522, 0.5191, 0.4729, 0.5317, 0.5085, 0.4776, 0.5567, 0.4869, 0.5376, 0.5526, 0.4168, 0.3758, 0.4725, 0.4159, 0.4485, 0.4862, 0.2781, 0.2545, 0.3682, 0.0868, 0.0791, 0.3153, 0.4688, 0.3416, 0.4092, -0.0237, 0.361, 0.4786, 0.0349, 0.0824, 0.2872, -0.2226, 0.1242, -0.3432, -0.4359, 1.6498, 1.6375, 1.6118, 1.5907, 1.5464, 1.5377, 1.5285, 1.5262, 1.5256, 1.5245, 1.5197, 1.5175, 1.5157, 1.5136, 1.5128, 1.5037, 1.489, 1.4847, 1.4727, 1.4722, 1.4707, 1.4697, 1.4689, 1.4663, 1.4648, 1.4645, 1.4609, 1.459, 1.4584, 1.4574, 1.4572, 1.4135, 1.4436, 1.3703, 1.3918, 1.3291, 1.3556, 1.4485, 1.353, 1.349, 1.2854, 1.1392, 1.2372, 0.7859, 1.1081, 1.032, 1.233, 0.7892, 0.7642, 0.9359, 0.5265, 0.4046, 1.1343, 0.8698, 0.2358, 0.2803, 0.6746, 0.7198, 0.1202, 0.8054, 0.6818, 0.723, 0.5938, 0.0932, -0.2499, 0.2438, -0.0435, 0.2345, 0.1048, -0.9214, 1.9223, 1.9162, 1.915, 1.9072, 1.9009, 1.9008, 1.9007, 1.8988, 1.8888, 1.8882, 1.885, 1.8773, 1.8772, 1.8772, 1.8772, 1.8771, 1.8771, 1.877, 1.8745, 1.8744, 1.8742, 1.8739, 1.8736, 1.873, 1.8722, 1.8709, 1.8411, 1.8148, 1.804, 1.7989, 1.7626, 1.7227, 1.0771, 1.7303, 1.6069, 1.5389, 1.2193, 1.4645, 1.2459, 0.7315, 0.8751, 0.4543, 1.1383, 0.2498, 0.4229, -0.0003, 0.1767, 0.6921, 0.2689, 1.0436, -0.2701, 0.5553, 0.4479, 0.7078, 1.1519, 1.9511, 1.9345, 1.9279, 1.9229, 1.9199, 1.919, 1.9106, 1.9031, 1.9026, 1.9017, 1.8842, 1.8755, 1.8752, 1.8683, 1.8679, 1.862, 1.8609, 1.8608, 1.8556, 1.8526, 1.8487, 1.8469, 1.8401, 1.8356, 1.8298, 1.827, 1.8259, 1.8203, 1.8184, 1.8175, 1.7903, 1.8066, 1.7049, 1.7693, 1.804, 1.7573, 1.6715, 1.7512, 1.6176, 1.4925, 1.7319, 1.4662, 1.3759, 1.7599, 1.7475, 1.2116, 1.1935, 1.4401, 1.6024, 1.4657, 1.2356, 0.5945, 1.2114, 1.334, 0.7239, 1.2782, 0.2829, 0.7779, 1.4558, 0.8423, 0.755, 0.1858, 1.121, -0.2014, -0.7635, -0.8656, -1.2202, 3.7688, 3.4345, 3.386, 3.2175, 3.0877, 2.9353, 2.9059, 2.88, 2.8798, 2.8792, 2.8545, 2.8533, 2.8531, 2.8526, 2.8504, 2.8493, 2.8493, 2.8491, 2.8478, 2.8467, 2.8235, 2.8225, 2.8224, 2.8222, 2.822, 2.822, 2.8217, 2.8216, 2.8215, 2.8213, 2.7245, 2.7587, 2.7292, 2.5673, 2.3627, 2.3222, 1.8718, 2.1191, 2.2909, 1.8738, 1.7503, 2.2904, 2.0334, 2.3137, 1.512, 1.9872, 0.9802, 0.8105, 1.5792, 0.9498, 1.2311, 0.0088, -0.3688, 0.0642]}, \"token.table\": {\"Topic\": [4, 2, 4, 2, 4, 4, 4, 4, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 2, 2, 1, 1, 2, 1, 2, 3, 4, 4, 3, 1, 3, 4, 1, 3, 1, 2, 3, 4, 3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 4, 1, 2, 1, 2, 4, 3, 4, 1, 2, 4, 2, 1, 4, 3, 3, 2, 1, 2, 3, 4, 1, 3, 4, 1, 2, 4, 3, 1, 3, 4, 1, 5, 4, 1, 2, 4, 4, 3, 3, 2, 5, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 5, 1, 3, 4, 5, 1, 2, 3, 4, 3, 2, 1, 2, 2, 2, 4, 1, 2, 4, 5, 3, 3, 4, 1, 2, 4, 3, 1, 1, 3, 5, 1, 3, 4, 2, 2, 3, 4, 1, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 1, 1, 5, 3, 3, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 5, 4, 1, 2, 3, 2, 1, 1, 2, 3, 5, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 1, 2, 3, 1, 2, 3, 4, 3, 2, 1, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 5, 2, 5, 4, 1, 2, 1, 3, 4, 2, 1, 5, 1, 2, 3, 2, 1, 5, 1, 2, 4, 3, 2, 4, 1, 2, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 1, 2, 4, 4, 1, 3, 1, 4, 2, 4, 1, 3, 5, 1, 1, 2, 4, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 4, 3, 2, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 4, 5, 4, 1, 1, 1, 4, 5, 4, 1, 2, 3, 4, 1, 2, 1, 1, 2, 1, 2, 3, 4, 2, 3, 1, 2, 1, 2, 3, 4, 1, 2, 2, 5, 3, 4, 1, 2, 5, 1, 2, 3, 1, 2, 4, 1, 2, 5, 3, 4, 3, 3, 1, 2, 1, 2, 3, 4, 3, 1, 4, 4, 3, 4, 4, 1, 5, 1, 1, 2, 1, 2, 3, 3, 1, 2, 1, 2, 3, 4, 4, 5, 1, 2, 3, 1, 2, 3, 5, 1, 3, 3, 1, 2, 3, 1, 3, 4, 2, 1, 1, 2, 3, 2, 3, 4, 5, 3, 4, 2, 1, 2, 3, 4, 1, 4, 1, 2, 3, 4, 1, 2, 4, 5, 1, 2, 3, 4, 2, 4, 5, 1, 2, 4, 2, 1, 1, 4, 1, 2, 3, 2, 4, 1, 3, 1, 2, 3, 4, 2, 1, 2, 3, 1, 4, 1, 4, 1, 3, 5, 4, 4, 2, 3, 1, 2, 2, 3, 2, 3, 5, 1, 1, 3, 4, 1, 1, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 3, 4, 1, 2, 3, 4], \"Freq\": [0.9434227124576173, 0.9277123361105558, 0.7640567239312351, 0.9375300033850907, 0.8960212228102924, 0.7532739382887789, 0.7542474664659374, 0.7539986427318934, 0.9319379926254379, 0.9722049640008574, 0.9545638839099226, 0.36681521220122604, 0.11004456366036781, 0.0733630424402452, 0.44017825464147126, 0.1919154453983473, 0.04797886134958682, 0.6717040588942156, 0.04797886134958682, 0.9443022979834035, 0.6379006856389617, 0.9684347557228462, 0.8425157803790315, 0.14867925536100557, 0.14591094052397155, 0.7295547026198577, 0.09727396034931436, 0.04863698017465718, 0.8561217436683956, 0.8718283868877849, 0.7927928170403062, 0.0428536657859625, 0.14998783025086876, 0.08995559651149455, 0.8995559651149456, 0.4213528688686602, 0.22982883756472375, 0.07660961252157458, 0.2872860469559047, 0.8729235985662012, 0.6461128589385798, 0.5700578811924144, 0.23441632497631992, 0.14384638123546906, 0.05327643749461816, 0.3612723320404357, 0.33869281128790846, 0.02257952075252723, 0.2709542490303268, 0.2123374874785943, 0.6900968343054315, 0.053084371869648574, 0.8160961701461295, 0.30852211320453315, 0.6170442264090663, 0.1746558223974439, 0.38424280927437654, 0.41917397375386534, 0.15245779993704198, 0.7622889996852098, 0.8031114669538286, 0.09560850797069388, 0.10516935876776326, 0.8715070730687273, 0.72402092708811, 0.26454610797450173, 0.8728337821415268, 0.9636699947657713, 0.8103785931605388, 0.8510163047826538, 0.06808130438261231, 0.06808130438261231, 0.017020326095653078, 0.2711904674665751, 0.18079364497771674, 0.5423809349331502, 0.24879891928277176, 0.5805308116598007, 0.1658659461885145, 0.8706704059657888, 0.9239916889320073, 0.13817004280649028, 0.8290202568389416, 0.6356641502016048, 0.3178320751008024, 0.9497195486610115, 0.421101413071992, 0.40751749652128255, 0.16979895688386773, 0.7985162370507607, 0.9169412249354059, 0.8728613611246118, 0.4517877117746854, 0.4517877117746854, 0.7546774272004606, 0.5424311143634679, 0.20341166788630047, 0.1840391280876052, 0.06780388929543349, 0.34127587618045013, 0.24283091189762795, 0.18376393332793467, 0.22970491665991835, 0.7709584010935205, 0.1284930668489201, 0.4800276795413836, 0.3600207596560377, 0.1200069198853459, 0.1200069198853459, 0.29964084309579336, 0.09988028103193111, 0.14982042154789668, 0.44946126464369, 0.9710829651214666, 0.9329191610694345, 0.14028095384283565, 0.8416857230570138, 0.9319722859808823, 0.09911705599106986, 0.8920535039196288, 0.05733160348729613, 0.37265542266742485, 0.5446502331293133, 0.5933899431089736, 0.8727919360932412, 0.15567218212397727, 0.7783609106198863, 0.2469260868026107, 0.5247179344555477, 0.21606032595228436, 0.8717133761457141, 0.9289326152914764, 0.964579826087954, 0.5185429831974446, 0.5185429831974446, 0.14730813160886524, 0.14730813160886524, 0.7365406580443262, 0.719435922267434, 0.8973718924189674, 0.8717959670560383, 0.8236300027167431, 0.4949016362973564, 0.4949016362973564, 0.9449855213597723, 0.26692437085070386, 0.11863305371142395, 0.4448739514178398, 0.17794958056713592, 0.10817305094641444, 0.576922938380877, 0.07211536729760963, 0.21634610189282888, 0.4995549549507484, 0.2497774774753742, 0.08325915915845807, 0.08325915915845807, 0.08325915915845807, 0.8593016748155988, 0.5758449303641275, 0.27781992254409665, 0.10607669769865508, 0.0404101705518686, 0.9883788927296073, 0.6900530302867682, 0.23001767676225607, 0.8715848820261509, 0.9104811690377173, 0.9580802844903632, 0.5731363794170159, 0.11895283346390896, 0.29197513668414016, 0.01081389395126445, 0.5722812629543855, 0.1962107187272179, 0.2289125051817542, 0.016350893227268157, 0.9390078930532695, 0.7400535063929197, 0.6512214856379946, 0.12481820940461097, 0.8737274658322768, 0.9495507028589028, 0.8871373939874782, 0.9757992199689011, 0.3069052797377728, 0.3069052797377728, 0.1534526398688864, 0.1534526398688864, 0.7464739783802681, 0.9775568056046614, 0.10008522398539617, 0.10008522398539617, 0.8006817918831693, 0.8942148432007521, 0.08318277611169786, 0.020795694027924465, 0.020795694027924465, 0.7570132767968654, 0.1577110993326803, 0.015771109933268027, 0.06308443973307211, 0.9525303777475099, 0.031751012591583666, 0.7429380060876727, 0.2311362685606093, 0.01650973346861495, 0.7766992223460567, 0.22574015521570173, 0.6320724346039648, 0.13544409312942104, 0.8726628653462803, 0.9111678966526396, 0.9604117815931964, 0.6783449471564533, 0.08809674638395498, 0.22024186595988746, 0.008809674638395498, 0.9763558406506977, 0.4735906442578178, 0.38338290249442397, 0.09020774176339387, 0.0676558063225454, 0.8825586652767439, 0.039517552176570624, 0.039517552176570624, 0.039517552176570624, 0.8642993740476199, 0.12347133914965999, 0.4795264261946903, 0.4795264261946903, 0.6514135453440713, 0.2269064822036029, 0.7941726877126102, 0.16042072607236582, 0.08021036303618291, 0.7218932673256462, 0.9445537958115401, 0.5735348219073468, 0.2867674109536734, 0.12606505266037815, 0.7563903159622688, 0.12606505266037815, 0.9504350127799815, 0.7437279195714767, 0.24790930652382556, 0.18966777454564976, 0.18966777454564976, 0.6638372109097742, 0.967348469566836, 0.6198643982177858, 0.3443691101209921, 0.9124540192309583, 0.08554256430290234, 0.7052806720244391, 0.017201967610352174, 0.2408275465449304, 0.03440393522070435, 0.9717417213269178, 0.17687502548596432, 0.15918752293736788, 0.07075001019438572, 0.5660000815550857, 0.9855854220477636, 0.12260276649525947, 0.2043379441587658, 0.6947490101398037, 0.8510891125486785, 0.9600441119354884, 0.03555718933094402, 0.9246837156353476, 0.8797786106837518, 0.7513160823918659, 0.15026321647837318, 0.9442171982981256, 0.036316046088389446, 0.5574397673664124, 0.9293978686446328, 0.9364091906491147, 0.028376036080276203, 0.028376036080276203, 0.9213852311536976, 0.8711010005572314, 0.7667506138083395, 0.1414394336151306, 0.05210926501610074, 0.029776722866343284, 0.88626538135823, 0.04598546790066287, 0.029263479573149103, 0.037624473736905986, 0.9527739278392001, 0.38329345392002445, 0.19997919334957798, 0.2833038572452355, 0.133319462233052, 0.05267900098796815, 0.17120675321089648, 0.06584875123496019, 0.71116651333757, 0.7995479854114829, 0.44567949009610547, 0.14855983003203516, 0.39615954675209375, 0.9409176395926424, 0.9315316260464284, 0.47013624415322774, 0.11753406103830694, 0.41136921363407425, 0.12948990680226674, 0.7121944874124672, 0.19423486020340014, 0.8718876217428604, 0.57639431626959, 0.20959793318894182, 0.10479896659447091, 0.10479896659447091, 0.052399483297235455, 0.829554667941569, 0.9797581109039588, 0.9628902453642684, 0.25401646410026474, 0.25401646410026474, 0.25401646410026474, 0.9434188920695818, 0.534320700681117, 0.15584353769865913, 0.28942371286893837, 0.022263362528379876, 0.20887849472249345, 0.8355139788899738, 0.9388959378684767, 0.9022696992002178, 0.06940536147693983, 0.2922271639306353, 0.01948181092870902, 0.15585448742967217, 0.5065270841464345, 0.8038358583495098, 0.1461519742453654, 0.6190424424374713, 0.3675564501972486, 0.7642212352802479, 0.0783816651569485, 0.11757249773542275, 0.03919083257847425, 0.8460349970534564, 0.13219296828960256, 0.9018724666527627, 0.7067475849724781, 0.24876534131932604, 0.7462960239579781, 0.43942350608243164, 0.21971175304121582, 0.21971175304121582, 0.19673278196221852, 0.7869311278488741, 0.06557759398740617, 0.8533309929142492, 0.08533309929142492, 0.06399982446856868, 0.3635195773160275, 0.5452793659740413, 0.060586596219337915, 0.12977031313656895, 0.7786218788194137, 0.9292023166627741, 0.8727862050182198, 0.6009447153345197, 0.3919204665225128, 0.39844436324176924, 0.39844436324176924, 0.09194869920963905, 0.09194869920963905, 0.87281743065839, 0.44164461881712563, 0.5152520552866465, 0.6962016811907639, 0.776407116305457, 0.14116493023735582, 0.9131304675824335, 0.8347150914105803, 0.13911918190176337, 0.9442007746698878, 0.5187619041042082, 0.4641553878827126, 0.17214658766011828, 0.6885863506404731, 0.08607329383005914, 0.9537200580402734, 0.9433507757148134, 0.9311908860895958, 0.09887245526993904, 0.4096144575468903, 0.056498545868536594, 0.4237390940140245, 0.7068046422969192, 0.3534023211484596, 0.4591952377341434, 0.07064542118986822, 0.4591952377341434, 0.34473504904934765, 0.34473504904934765, 0.34473504904934765, 0.34473504904934765, 0.9859663114062605, 0.9207514385603458, 0.9207662892226867, 0.8182794005451152, 0.09263540383529606, 0.07719616986274672, 0.5179736541172255, 0.3399202105144293, 0.12949341352930638, 0.8290044483146102, 0.9849472609722436, 0.35670811081246795, 0.14862837950519497, 0.5053364903176629, 0.25234125293932314, 0.07209750083980661, 0.6488775075582595, 0.036048750419903304, 0.19012918870871354, 0.7605167548348541, 0.9562514251828401, 0.3713520662048346, 0.2084783529571001, 0.4169567059142002, 0.8512492304177787, 0.08020898643556969, 0.8822988507912666, 0.5490935560527258, 0.015252598779242383, 0.015252598779242383, 0.4270727658187868, 0.7921025698002461, 0.1523274172692781, 0.030465483453855618, 0.030465483453855618, 0.10106536857404154, 0.35372879000914537, 0.25266342143510384, 0.30319610572212463, 0.7827832947094112, 0.7835863456141496, 0.7008194604779124, 0.8460271325966894, 0.1208610189423842, 0.021974730716797126, 0.8280983596679224, 0.9901105671141568, 0.22305371400607896, 0.7806879990212764, 0.12847469859575592, 0.7708481915745355, 0.12847469859575592, 0.7291550755720756, 0.2083300215920216, 0.9664915897397094, 0.8713568731324868, 0.8517534406620482, 0.06759947941762287, 0.013519895883524573, 0.06759947941762287, 0.9505660224369096, 0.279315763648668, 0.2285310793489102, 0.4824545008476993, 0.22961064319974045, 0.6888319295992213, 0.4244319153800431, 0.5456981769171982, 0.5033411144510765, 0.33556074296738436, 0.16778037148369218, 0.7745737847295727, 0.7916225156314536, 0.14615616677341456, 0.8403979589471338, 0.9257537575692921, 0.03428717620627008, 0.09482647880983991, 0.9008515486934792, 0.4863627437493074, 0.2431813718746537, 0.2431813718746537, 0.9617588954245242, 0.9040364999640863, 0.03477063461400332, 0.03477063461400332, 0.9543971932724155, 0.09005223369403928, 0.8104701032463535, 0.6834779029770625, 0.24853741926438636, 0.06213435481609659, 0.020711451605365527, 0.8443624602390697, 0.07085559106901285, 0.023618530356337614, 0.05904632589084404, 0.9330442612533136, 0.799659372004467, 0.04442552066691483, 0.15548932233420193, 0.6956897368787391, 0.06324452153443083, 0.21683835954661998, 0.027104794943327497, 0.5155195006326121, 0.31072408257308126, 0.1694858632216807, 0.5274076240454233, 0.4482964804386098, 0.026370381202271163, 0.8775110015864828, 0.016556811350688354, 0.09934086810413013, 0.1167814219947331, 0.029195355498683274, 0.08758606649604982, 0.7590792429657651], \"Term\": [\"101-102\", \"139-140\", \"193-199\", \"25-26\", \"34-35\", \"37-39\", \"44-45\", \"45-46\", \"_sex\", \"aleck\", \"alfred\", \"also\", \"also\", \"also\", \"also\", \"american\", \"american\", \"american\", \"american\", \"announcement\", \"antagonism\", \"away\", \"back\", \"back\", \"book\", \"book\", \"book\", \"book\", \"brandt\", \"brief\", \"bring\", \"bring\", \"bring\", \"broken\", \"broken\", \"bureau\", \"bureau\", \"bureau\", \"bureau\", \"byron\", \"capacity\", \"case\", \"case\", \"case\", \"case\", \"cause\", \"cause\", \"cause\", \"cause\", \"cent\", \"cent\", \"cent\", \"ceremony\", \"character\", \"character\", \"charity\", \"charity\", \"charity\", \"chicago\", \"chicago\", \"child\", \"child\", \"child\", \"choose\", \"city\", \"city\", \"cloth\", \"colcord\", \"combine\", \"come\", \"come\", \"come\", \"come\", \"common\", \"common\", \"common\", \"community\", \"community\", \"community\", \"compass\", \"complaint\", \"conference\", \"conference\", \"content\", \"content\", \"correction\", \"court\", \"court\", \"court\", \"crisis\", \"cross\", \"deacon\", \"demand\", \"demand\", \"depend\", \"deserter\", \"deserter\", \"deserter\", \"deserter\", \"desertion\", \"desertion\", \"desertion\", \"desertion\", \"desire\", \"desire\", \"develop\", \"develop\", \"develop\", \"develop\", \"difference\", \"difference\", \"difference\", \"difference\", \"disaster\", \"disintegrate\", \"disposition\", \"disposition\", \"distinct\", \"divorce\", \"divorce\", \"domestic\", \"domestic\", \"domestic\", \"donald\", \"ebook\", \"educational\", \"educational\", \"effect\", \"effect\", \"effect\", \"embody\", \"employment\", \"enough\", \"envelope\", \"envelope\", \"equity\", \"equity\", \"equity\", \"examination\", \"expert\", \"expression\", \"extradite\", \"extradition\", \"extradition\", \"facility\", \"fact\", \"fact\", \"fact\", \"fact\", \"factor\", \"factor\", \"factor\", \"factor\", \"failure\", \"failure\", \"failure\", \"failure\", \"failure\", \"false\", \"family\", \"family\", \"family\", \"family\", \"father\", \"feeling\", \"feeling\", \"fewer--having\", \"field\", \"finally\", \"find\", \"find\", \"find\", \"find\", \"first\", \"first\", \"first\", \"first\", \"florence\", \"footnote\", \"forel\", \"forward\", \"forward\", \"foundation\", \"frequently\", \"friend\", \"future\", \"future\", \"future\", \"future\", \"gamble\", \"gather\", \"general\", \"general\", \"general\", \"get\", \"get\", \"get\", \"get\", \"give\", \"give\", \"give\", \"give\", \"go\", \"go\", \"good\", \"good\", \"good\", \"gradually\", \"group\", \"group\", \"group\", \"gutenberg\", \"hebrew\", \"help\", \"home\", \"home\", \"home\", \"home\", \"household\", \"however\", \"however\", \"however\", \"however\", \"husband\", \"husband\", \"husband\", \"husband\", \"ill\", \"ill\", \"imagination\", \"imagination\", \"immorality\", \"income\", \"income\", \"incompatibility\", \"incompatibility\", \"incompatibility\", \"inferiority\", \"instability\", \"instability\", \"interference\", \"interference\", \"interference\", \"issue\", \"jealousy\", \"jealousy\", \"jewish\", \"jewish\", \"jewish\", \"joanna\", \"juvenile\", \"juvenile\", \"keep\", \"keep\", \"know\", \"know\", \"know\", \"know\", \"later\", \"law\", \"law\", \"law\", \"law\", \"leave\", \"legal\", \"legal\", \"legal\", \"legislation\", \"letter\", \"letter\", \"likely\", \"lilian\", \"list\", \"list\", \"little\", \"little\", \"loane\", \"local\", \"long\", \"long\", \"long\", \"longer\", \"lucidly\", \"make\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"man\", \"management\", \"many\", \"many\", \"many\", \"many\", \"marriage\", \"marriage\", \"marriage\", \"marriage\", \"marriages\", \"marry\", \"marry\", \"marry\", \"mary\", \"mellor\", \"men\", \"men\", \"men\", \"mental\", \"mental\", \"mental\", \"message\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"misdemeanor\", \"money\", \"month\", \"motif\", \"motif\", \"motif\", \"motion\", \"much\", \"much\", \"much\", \"much\", \"municipal\", \"municipal\", \"nesbitt\", \"never\", \"never\", \"new\", \"new\", \"new\", \"new\", \"number\", \"number\", \"officer\", \"officer\", \"often\", \"often\", \"often\", \"often\", \"order\", \"order\", \"organize\", \"patrick\", \"percentage\", \"percentage\", \"perhaps\", \"perhaps\", \"perhaps\", \"philadelphia\", \"philadelphia\", \"philadelphia\", \"place\", \"place\", \"place\", \"poor\", \"poor\", \"poor\", \"pregnancy\", \"pregnancy\", \"preparation\", \"price\", \"probation\", \"probation\", \"problem\", \"problem\", \"problem\", \"problem\", \"project\", \"protection\", \"protection\", \"protective\", \"publication\", \"publication\", \"racial\", \"realize\", \"realize\", \"receive\", \"reconciliation\", \"reconciliation\", \"recreation\", \"recreation\", \"recreation\", \"red\", \"refuse\", \"rehabilitation\", \"relation\", \"relation\", \"relation\", \"relation\", \"relationship\", \"relationship\", \"relief\", \"relief\", \"relief\", \"resort\", \"resort\", \"resort\", \"resort\", \"return\", \"russell\", \"sage\", \"say\", \"say\", \"say\", \"see\", \"see\", \"see\", \"self-control\", \"send\", \"service\", \"service\", \"service\", \"sex\", \"sex\", \"sex\", \"sex\", \"sexual\", \"sexual\", \"seybert\", \"social\", \"social\", \"social\", \"spouse\", \"st\", \"st\", \"state\", \"state\", \"state\", \"state\", \"story\", \"story\", \"story\", \"story\", \"study\", \"study\", \"study\", \"study\", \"subsequent\", \"summary\", \"survive\", \"take\", \"take\", \"take\", \"teach\", \"tell\", \"term\", \"term\", \"testimony\", \"testimony\", \"testimony\", \"therefore\", \"therefore\", \"think\", \"this--can\", \"time\", \"time\", \"time\", \"time\", \"training\", \"treatment\", \"treatment\", \"treatment\", \"treaty\", \"treaty\", \"union\", \"union\", \"urge\", \"urge\", \"urge\", \"vagary\", \"verification\", \"view\", \"view\", \"visitor\", \"visitor\", \"volume\", \"volume\", \"wanderlust\", \"wanderlust\", \"wanderlust\", \"want\", \"way\", \"way\", \"way\", \"week\", \"welfare\", \"welfare\", \"well\", \"well\", \"well\", \"well\", \"wife\", \"wife\", \"wife\", \"wife\", \"willing\", \"woman\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"worker\", \"write\", \"write\", \"write\", \"year\", \"year\", \"year\", \"york\", \"york\", \"york\", \"york\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 2, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el21981397808389411361870018081\", ldavis_el21981397808389411361870018081_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el21981397808389411361870018081\", ldavis_el21981397808389411361870018081_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el21981397808389411361870018081\", ldavis_el21981397808389411361870018081_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
              "topic                                                    \n",
              "3      150.222153  -72.269554       1        1  52.668129\n",
              "0       51.163364 -159.968018       2        1  18.489188\n",
              "2      -73.144554   21.523815       3        1  14.156126\n",
              "1      -66.410133 -110.606438       4        1  12.810701\n",
              "4       54.417324   12.443444       5        1   1.875856, topic_info=           Term        Freq       Total Category  logprob  loglift\n",
              "3155     social  153.000000  153.000000  Default  30.0000  30.0000\n",
              "2175   marriage   75.000000   75.000000  Default  29.0000  29.0000\n",
              "888       court  147.000000  147.000000  Default  28.0000  28.0000\n",
              "3226      state   65.000000   65.000000  Default  27.0000  27.0000\n",
              "1020  desertion  152.000000  152.000000  Default  26.0000  26.0000\n",
              "...         ...         ...         ...      ...      ...      ...\n",
              "1401    failure    0.582447   12.010691   Topic5  -6.4291   0.9498\n",
              "1765        ill    0.520338    8.099046   Topic5  -6.5419   1.2311\n",
              "3257      story    0.621198   32.824032   Topic5  -6.3647   0.0088\n",
              "3715       well    0.626346   48.282468   Topic5  -6.3564  -0.3688\n",
              "3085        sex    0.554879   27.740213   Topic5  -6.4776   0.0642\n",
              "\n",
              "[344 rows x 6 columns], token_table=      Topic      Freq     Term\n",
              "term                          \n",
              "0         4  0.943423  101-102\n",
              "24        2  0.927712  139-140\n",
              "54        4  0.764057  193-199\n",
              "61        2  0.937530    25-26\n",
              "67        4  0.896021    34-35\n",
              "...     ...       ...      ...\n",
              "3793      4  0.099341     year\n",
              "3800      1  0.116781     york\n",
              "3800      2  0.029195     york\n",
              "3800      3  0.087586     york\n",
              "3800      4  0.759079     york\n",
              "\n",
              "[523 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Which vectorization method performed better?"
      ],
      "metadata": {
        "id": "0DMHPrsbLjFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [\n",
        "    {\n",
        "        'method': 'BoW',\n",
        "        'Log Likelihood': bow_pipeline.score(docs),\n",
        "        'Perplexity': bow_pipeline['lda'].perplexity(bow_pipeline['bow'].transform(docs))\n",
        "    },\n",
        "    {\n",
        "        'method': 'TF-IDF',\n",
        "        'Log Likelihood': tfidf_pipeline.score(docs),\n",
        "        'Perplexity': tfidf_pipeline['lda'].perplexity(tfidf_pipeline['tfidf'].transform(docs))\n",
        "    }\n",
        "]\n",
        "pd.DataFrame.from_records(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "ixFSbotCVGZf",
        "outputId": "4a78ca8a-b246-4423-a81c-f6c3dbe65bd0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c8ce11bb-c2a6-473d-abf5-6d3ba429fb42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>Log Likelihood</th>\n",
              "      <th>Perplexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BoW</td>\n",
              "      <td>-146026.155543</td>\n",
              "      <td>1978.534149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>-25222.619218</td>\n",
              "      <td>11524.046674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8ce11bb-c2a6-473d-abf5-6d3ba429fb42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8ce11bb-c2a6-473d-abf5-6d3ba429fb42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8ce11bb-c2a6-473d-abf5-6d3ba429fb42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   method  Log Likelihood    Perplexity\n",
              "0     BoW  -146026.155543   1978.534149\n",
              "1  TF-IDF   -25222.619218  11524.046674"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of `Log Likelihood`, TF-IDF is better (higher value), but in terms of `Perplexity`, TF-IDF is worse (higher vlaue)."
      ],
      "metadata": {
        "id": "GWzH2L4hWLMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Compare the results with different topic classification models."
      ],
      "metadata": {
        "id": "5ILRyEA6LhmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_method(model, name, docs):\n",
        "    model = Pipeline([\n",
        "        ('vectorizer', TfidfVectorizer(\n",
        "            tokenizer=tokenizer,\n",
        "            stop_words=stopwords.words('english')\n",
        "        )),\n",
        "        (\"lda\", model)\n",
        "    ])\n",
        "    model.fit(docs)\n",
        "    return {\n",
        "        'method': name,\n",
        "        'Log Likelihood': model.score(docs),\n",
        "        'Perplexity': model['topic_model'].perplexity(model['vectorizer'].transform(docs))\n",
        "    }"
      ],
      "metadata": {
        "id": "mE5fMTPLLg-M"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coherence(model, texts, dictionary):\n",
        "    \"\"\"\n",
        "    Get coherence score from model.\n",
        "    \"\"\"\n",
        "    coherence_model = CoherenceModel(\n",
        "        model=model,\n",
        "        texts=texts,\n",
        "        dictionary=dictionary,\n",
        "        coherence='c_v'\n",
        "    )\n",
        "    return coherence_model.get_coherence()"
      ],
      "metadata": {
        "id": "XhU8zsHrP9Cu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model, corpus, id2word):\n",
        "    \"\"\"\n",
        "    Construct model using `gensim` topic model classes\n",
        "    \"\"\"\n",
        "    return model(\n",
        "        corpus=corpus,\n",
        "        id2word=id2word,\n",
        "        num_topics=5,\n",
        "        chunksize=100\n",
        "    )"
      ],
      "metadata": {
        "id": "JOJnEfe8RvMA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(model, pipe):\n",
        "    \"\"\"\n",
        "    Evaluate methods and pipelines\n",
        "    \"\"\"\n",
        "    tokens=[\n",
        "        list(token)\n",
        "        for token\n",
        "        in pipe['bow'].inverse_transform(pipe['bow'].transform(docs))\n",
        "    ]\n",
        "    id2word = gensim.corpora.Dictionary(tokens)\n",
        "    corpus = [id2word.doc2bow(token) for token in tokens]\n",
        "    return get_coherence(\n",
        "        model=get_model(\n",
        "            model=model,\n",
        "            corpus=corpus,\n",
        "            id2word=id2word),\n",
        "        texts=tokens,\n",
        "        dictionary=id2word,\n",
        "    )"
      ],
      "metadata": {
        "id": "g3Wf1TOsTk4L"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'LDA': gensim.models.ldamodel.LdaModel,\n",
        "    'NMF': gensim.models.nmf.Nmf,\n",
        "    'LSA': gensim.models.lsimodel.LsiModel\n",
        "}\n",
        "res = [\n",
        "    {\n",
        "        'Model': name,\n",
        "        'Coherence Score': get_score(module, bow_pipeline)\n",
        "    }\n",
        "    for name, module in models.items()\n",
        "]"
      ],
      "metadata": {
        "id": "9N_-ogq7SWDJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_records(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "KnzAWyqLxx2f",
        "outputId": "8aa45f75-64bb-4b12-bdc1-ff1011a6ce4a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f31f97df-c3b5-48c2-aa15-f1192e5bcb47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Coherence Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LDA</td>\n",
              "      <td>0.365173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NMF</td>\n",
              "      <td>0.648223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LSA</td>\n",
              "      <td>0.698994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f31f97df-c3b5-48c2-aa15-f1192e5bcb47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f31f97df-c3b5-48c2-aa15-f1192e5bcb47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f31f97df-c3b5-48c2-aa15-f1192e5bcb47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Model  Coherence Score\n",
              "0   LDA         0.365173\n",
              "1   NMF         0.648223\n",
              "2   LSA         0.698994"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. (optional) use random search or grid search to optimize the number of topics."
      ],
      "metadata": {
        "id": "qUxX6ZdSLabt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gs = GridSearchCV(\n",
        "    tfidf_pipeline,\n",
        "    param_grid={\n",
        "        'lda__n_components': [3, 4, 5, 6]\n",
        "    }\n",
        ")\n",
        "\n",
        "gs.fit(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWn5fBKTJtie",
        "outputId": "d1d7ef77-7ea9-4d01-e630-275a0edd2d08"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
              "                                        TfidfVectorizer(stop_words=['i', 'me',\n",
              "                                                                    'my',\n",
              "                                                                    'myself',\n",
              "                                                                    'we', 'our',\n",
              "                                                                    'ours',\n",
              "                                                                    'ourselves',\n",
              "                                                                    'you',\n",
              "                                                                    \"you're\",\n",
              "                                                                    \"you've\",\n",
              "                                                                    \"you'll\",\n",
              "                                                                    \"you'd\",\n",
              "                                                                    'your',\n",
              "                                                                    'yours',\n",
              "                                                                    'yourself',\n",
              "                                                                    'yourselves',\n",
              "                                                                    'he', 'him',\n",
              "                                                                    'his',\n",
              "                                                                    'himself',\n",
              "                                                                    'she',\n",
              "                                                                    \"she's\",\n",
              "                                                                    'her',\n",
              "                                                                    'hers',\n",
              "                                                                    'herself',\n",
              "                                                                    'it',\n",
              "                                                                    \"it's\",\n",
              "                                                                    'its',\n",
              "                                                                    'itself', ...],\n",
              "                                                        tokenizer=<function tokenizer at 0x7f214b52a560>)),\n",
              "                                       ('lda',\n",
              "                                        LatentDirichletAllocation(learning_method='online',\n",
              "                                                                  n_components=5,\n",
              "                                                                  n_jobs=-1,\n",
              "                                                                  random_state=100))]),\n",
              "             param_grid={'lda__n_components': [3, 4, 5, 6]})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnTIhCku02Y-",
        "outputId": "746e6223-5261-463e-afc1-e0d3952062b2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lda__n_components': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(\n",
        "    gs.cv_results_['param_lda__n_components'].data,\n",
        "    gs.cv_results_['mean_test_score']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "qSoSV-iS1zQG",
        "outputId": "7b39960d-fbfa-47ed-876b-550f4db864d6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f213beeaa10>]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs.cv_results_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0isXoVx1JP2",
        "outputId": "82763ef1-fcd2-4206-d0b5-5f40f3711bcd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([3.14027996, 3.03638988, 3.09495401, 3.27594309, 3.42959924,\n",
              "        3.58529329]),\n",
              " 'mean_score_time': array([0.46489363, 0.44774923, 0.45874119, 0.46287751, 0.45386505,\n",
              "        0.46877632]),\n",
              " 'mean_test_score': array([ -5912.25391374,  -7282.86757851,  -8142.04570777,  -9242.12323519,\n",
              "        -10557.48635448, -11704.81409571]),\n",
              " 'param_lda__n_components': masked_array(data=[5, 10, 15, 20, 25, 30],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'lda__n_components': 5},\n",
              "  {'lda__n_components': 10},\n",
              "  {'lda__n_components': 15},\n",
              "  {'lda__n_components': 20},\n",
              "  {'lda__n_components': 25},\n",
              "  {'lda__n_components': 30}],\n",
              " 'rank_test_score': array([1, 2, 3, 4, 5, 6], dtype=int32),\n",
              " 'split0_test_score': array([ -6516.80457004,  -7717.77695331,  -8755.80613511, -10124.69629335,\n",
              "        -12748.94773864, -13274.29454305]),\n",
              " 'split1_test_score': array([ -7170.94890879,  -8495.41242348,  -9190.26669411, -10163.59616324,\n",
              "        -10976.46136798, -12407.83090675]),\n",
              " 'split2_test_score': array([ -6389.33484026,  -7783.41873331,  -8860.9913664 ,  -9564.45356807,\n",
              "        -10969.61595234, -11750.87017152]),\n",
              " 'split3_test_score': array([ -5169.53499972,  -6485.2707503 ,  -7330.02420962,  -8857.55394268,\n",
              "         -9492.1854073 , -10929.02020869]),\n",
              " 'split4_test_score': array([ -4314.64624991,  -5932.45903215,  -6573.14013359,  -7500.31620861,\n",
              "         -8600.22130616, -10162.05464856]),\n",
              " 'std_fit_time': array([0.29796214, 0.26063833, 0.18866901, 0.216194  , 0.22164411,\n",
              "        0.23445658]),\n",
              " 'std_score_time': array([0.19476716, 0.17705672, 0.18039652, 0.1878312 , 0.18760051,\n",
              "        0.18000338]),\n",
              " 'std_test_score': array([1027.75312501,  934.85042294, 1011.25620617,  991.33542882,\n",
              "        1422.22687663, 1090.0995863 ])}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Upload your notebook to project2 branch of the course github repo"
      ],
      "metadata": {
        "id": "RnT0McH-LGi7"
      }
    }
  ]
}